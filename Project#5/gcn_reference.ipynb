{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"59RM0FQwq6ye","colab_type":"code","outputId":"a10f5c9e-a4c5-4a64-a371-0627f88db628","executionInfo":{"status":"ok","timestamp":1576907456238,"user_tz":-540,"elapsed":24982,"user":{"displayName":"Jinwoo Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhgJSHrbMreTqBnmwR9bPABANy6TFKVVUvgM3_Gg=s64","userId":"09499597083311632056"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["# connect to google drive\n","from google.colab import drive\n","\n","drive.mount('/gdrive')\n","gdrive_root = '/gdrive/My Drive'\n","\n","########################################################################################\n","# SET WORKING DIRECTORY TO PROJECT FOLDER BEFORE RUNNING!!\n","wd = gdrive_root + '/BiS438 bioinformatics working directory/Project#5/'\n","########################################################################################"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EN8eL-5vqn6u","colab_type":"code","outputId":"abd22898-cc8f-4cf8-c54c-d585ef017ee1","executionInfo":{"status":"ok","timestamp":1576907462172,"user_tz":-540,"elapsed":4220,"user":{"displayName":"Jinwoo Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhgJSHrbMreTqBnmwR9bPABANy6TFKVVUvgM3_Gg=s64","userId":"09499597083311632056"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["from __future__ import division\n","from __future__ import print_function\n","\n","import time\n","\n","import numpy as np\n","import scipy.sparse as sp\n","\n","import networkx as nx\n","import tensorflow as tf\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import average_precision_score"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"0rlpFl9vquuX","colab_type":"code","colab":{}},"source":["# set random seed\n","seed = 1\n","np.random.seed(seed)\n","tf.set_random_seed(seed)\n","\n","# set hyperparameters\n","flags = tf.app.flags\n","FLAGS = flags.FLAGS\n","flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n","flags.DEFINE_integer('epochs', 20, 'Number of epochs to train.')\n","flags.DEFINE_integer('hidden1', 32, 'Number of units in hidden layer 1.')\n","flags.DEFINE_integer('hidden2', 16, 'Number of units in hidden layer 2.')\n","flags.DEFINE_float('dropout', 0.1, 'Dropout rate (1 - keep probability).')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sjxJk-qJqwfT","colab_type":"code","colab":{}},"source":["def load_data():\n","  g = nx.read_edgelist(wd + 'yeast.edgelist.txt')\n","  # g: networkx Graph object\n","  adj = nx.adjacency_matrix(g)\n","  # adj: SciPy sparse matrix\n","  return adj\n","\n","\n","def weight_variable_glorot(input_dim, output_dim, name=\"\"):\n","  init_range = np.sqrt(6.0 / (input_dim + output_dim))\n","  initial = tf.random_uniform(\n","    [input_dim, output_dim], minval=-init_range,\n","    maxval=init_range, dtype=tf.float32)\n","  # initialized, fully-connected weight matrix\n","  return tf.Variable(initial, name=name)\n","\n","\n","def dropout_sparse(x, keep_prob, num_nonzero_elems):\n","    noise_shape = [num_nonzero_elems]\n","    random_tensor = keep_prob\n","    random_tensor += tf.random_uniform(noise_shape)\n","    dropout_mask = tf.cast(tf.floor(random_tensor), dtype=tf.bool)\n","    pre_out = tf.sparse_retain(x, dropout_mask)\n","    return pre_out * (1. / keep_prob)\n","\n","\n","def sparse_to_tuple(sparse_mx):\n","    if not sp.isspmatrix_coo(sparse_mx):\n","        sparse_mx = sparse_mx.tocoo()\n","    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n","    values = sparse_mx.data\n","    shape = sparse_mx.shape\n","    return coords, values, shape\n","\n","\n","def preprocess_graph(adj):\n","    adj = sp.coo_matrix(adj) # adj: sparse matrix in COO format\n","    adj_ = adj + sp.eye(adj.shape[0]) # sp.eye returns a sparse matrix\n","    rowsum = np.array(adj_.sum(1))\n","    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n","    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n","    # adj_normalized: sparse normalized matrix\n","    return sparse_to_tuple(adj_normalized)\n","\n","\n","def construct_feed_dict(adj_normalized, adj, features, placeholders):\n","    feed_dict = dict()\n","    feed_dict.update({placeholders['features']: features})\n","    feed_dict.update({placeholders['adj']: adj_normalized})\n","    feed_dict.update({placeholders['adj_orig']: adj})\n","    return feed_dict\n","\n","\n","def mask_test_edges(adj):\n","    # Function to build test set with 2% positive links\n","    # Remove diagonal elements\n","    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n","    adj.eliminate_zeros()\n","\n","    adj_triu = sp.triu(adj)\n","    adj_tuple = sparse_to_tuple(adj_triu)\n","    edges = adj_tuple[0]\n","    edges_all = sparse_to_tuple(adj)[0]\n","    num_test = int(np.floor(edges.shape[0] / 50.))\n","    num_val = int(np.floor(edges.shape[0] / 50.))\n","\n","    all_edge_idx = np.linspace(0,edges.shape[0],edges.shape[0],endpoint=False).astype(int)\n","    np.random.shuffle(all_edge_idx)\n","    val_edge_idx = all_edge_idx[:num_val]\n","    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n","    test_edges = edges[test_edge_idx]\n","    val_edges = edges[val_edge_idx]\n","    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n","\n","    def ismember(a, b):\n","        rows_close = np.all((a - b[:, None]) == 0, axis=-1)\n","        return np.any(rows_close)\n","\n","    test_edges_false = []\n","    while len(test_edges_false) < len(test_edges):\n","        n_rnd = len(test_edges) - len(test_edges_false)\n","        rnd = np.random.randint(0, adj.shape[0], size=2 * n_rnd)\n","        idxs_i = rnd[:n_rnd]                                        \n","        idxs_j = rnd[n_rnd:]\n","        for i in range(n_rnd):\n","            idx_i = idxs_i[i]\n","            idx_j = idxs_j[i]\n","            if idx_i == idx_j:\n","                continue\n","            if ismember([idx_i, idx_j], edges_all):\n","                continue\n","            if test_edges_false:\n","                if ismember([idx_j, idx_i], np.array(test_edges_false)):\n","                    continue\n","                if ismember([idx_i, idx_j], np.array(test_edges_false)):\n","                    continue\n","            test_edges_false.append([idx_i, idx_j])\n","\n","    val_edges_false = []\n","    while len(val_edges_false) < len(val_edges):\n","        n_rnd = len(val_edges) - len(val_edges_false)\n","        rnd = np.random.randint(0, adj.shape[0], size=2 * n_rnd)\n","        idxs_i = rnd[:n_rnd]                                        \n","        idxs_j = rnd[n_rnd:]\n","        for i in range(n_rnd):\n","            idx_i = idxs_i[i]\n","            idx_j = idxs_j[i]\n","            if idx_i == idx_j:\n","                continue\n","            if ismember([idx_i, idx_j], train_edges):\n","                continue\n","            if ismember([idx_j, idx_i], train_edges):\n","                continue\n","            if ismember([idx_i, idx_j], val_edges):\n","                continue\n","            if ismember([idx_j, idx_i], val_edges):\n","                continue\n","            if val_edges_false:\n","                if ismember([idx_j, idx_i], np.array(val_edges_false)):\n","                    continue\n","                if ismember([idx_i, idx_j], np.array(val_edges_false)):\n","                    continue\n","            val_edges_false.append([idx_i, idx_j])\n","\n","    # Re-build adj matrix\n","    data = np.ones(train_edges.shape[0])\n","    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n","    adj_train = adj_train + adj_train.T\n","\n","    return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false\n","\n","\n","def get_roc_score(edges_pos, edges_neg):\n","    feed_dict.update({placeholders['dropout']: 0})\n","    emb = sess.run(model.embeddings, feed_dict=feed_dict)\n","\n","    def sigmoid(x):\n","        return 1 / (1 + np.exp(-x))\n","\n","    # Predict on test set of edges\n","    adj_rec = np.dot(emb, emb.T)\n","    preds = []\n","    pos = []\n","    for e in edges_pos:\n","        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n","        pos.append(adj_orig[e[0], e[1]])\n","\n","    preds_neg = []\n","    neg = []\n","    for e in edges_neg:\n","        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n","        neg.append(adj_orig[e[0], e[1]])\n","\n","    preds_all = np.hstack([preds, preds_neg])\n","    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds))])\n","    roc_score = roc_auc_score(labels_all, preds_all)\n","    ap_score = average_precision_score(labels_all, preds_all)\n","\n","    return roc_score, ap_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fz2GI6ZqrEB4","colab_type":"code","colab":{}},"source":["class GraphConvolution():\n","    \"\"\"Basic graph convolution layer for undirected graph without edge labels.\"\"\"\n","    def __init__(self, input_dim, output_dim, adj, name, dropout=0., act=tf.nn.relu):\n","        self.name = name\n","        self.vars = {}\n","        self.issparse = False\n","        with tf.variable_scope(self.name + '_vars'):\n","            self.vars['weights'] = weight_variable_glorot(input_dim, output_dim, name='weights')\n","        self.dropout = dropout\n","        self.adj = adj\n","        self.act = act\n","\n","    def __call__(self, inputs):\n","        with tf.name_scope(self.name):        \n","            x = inputs\n","            x = tf.nn.dropout(x, 1-self.dropout)\n","            x = tf.matmul(x, self.vars['weights'])\n","            x = tf.sparse_tensor_dense_matmul(self.adj, x)\n","            outputs = self.act(x)\n","        return outputs\n","\n","\n","class GraphConvolutionSparse():\n","    \"\"\"Graph convolution layer for sparse inputs.\"\"\"\n","    def __init__(self, input_dim, output_dim, adj, features_nonzero, name, dropout=0., act=tf.nn.relu):\n","        self.name = name\n","        self.vars = {}\n","        self.issparse = False\n","        with tf.variable_scope(self.name + '_vars'):\n","            self.vars['weights'] = weight_variable_glorot(input_dim, output_dim, name='weights')\n","        self.dropout = dropout\n","        self.adj = adj\n","        self.act = act\n","        self.issparse = True\n","        self.features_nonzero = features_nonzero\n","\n","    def __call__(self, inputs):\n","        with tf.name_scope(self.name):\n","            x = inputs\n","            x = dropout_sparse(x, 1-self.dropout, self.features_nonzero)\n","            x = tf.sparse_tensor_dense_matmul(x, self.vars['weights'])\n","            x = tf.sparse_tensor_dense_matmul(self.adj, x)\n","            outputs = self.act(x)\n","        return outputs\n","    \n","    \n","class InnerProductDecoder():\n","    \"\"\"Decoder model layer for link prediction.\"\"\"\n","    def __init__(self, input_dim, name, dropout=0., act=tf.nn.sigmoid):\n","        self.name = name\n","        self.issparse = False\n","        self.dropout = dropout\n","        self.act = act\n","\n","    def __call__(self, inputs):\n","        with tf.name_scope(self.name):\n","            inputs = tf.nn.dropout(inputs, 1-self.dropout)\n","            x = tf.transpose(inputs)\n","            x = tf.matmul(inputs, x)\n","            x = tf.reshape(x, [-1])\n","            outputs = self.act(x)\n","        return outputs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uI4eIS1ErF9-","colab_type":"code","colab":{}},"source":["class GCNModel():\n","    def __init__(self, placeholders, num_features, features_nonzero, name):\n","        self.name = name\n","        self.inputs = placeholders['features']\n","        self.input_dim = num_features\n","        self.features_nonzero = features_nonzero\n","        self.adj = placeholders['adj']\n","        self.dropout = placeholders['dropout']\n","        with tf.variable_scope(self.name):\n","            self.build()\n","        \n","    def build(self):\n","        self.hidden1 = GraphConvolutionSparse(\n","            name='gcn_sparse_layer',\n","            input_dim=self.input_dim,\n","            output_dim=FLAGS.hidden1,\n","            adj=self.adj,\n","            features_nonzero=self.features_nonzero,\n","            act=tf.nn.relu,\n","            dropout=self.dropout)(self.inputs)\n","\n","        self.embeddings = GraphConvolution(\n","            name='gcn_dense_layer',\n","            input_dim=FLAGS.hidden1,\n","            output_dim=FLAGS.hidden2,\n","            adj=self.adj,\n","            act=lambda x: x,\n","            dropout=self.dropout)(self.hidden1)\n","\n","        self.reconstructions = InnerProductDecoder(\n","            name='gcn_decoder',\n","            input_dim=FLAGS.hidden2, \n","            act=lambda x: x)(self.embeddings)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lXqOKoi9rODN","colab_type":"code","colab":{}},"source":["class Optimizer():\n","    def __init__(self, preds, labels, num_nodes, num_edges):\n","        pos_weight = float(num_nodes**2 - num_edges) / num_edges\n","        norm = num_nodes**2 / float((num_nodes**2 - num_edges) * 2)\n","        \n","        preds_sub = preds\n","        labels_sub = labels\n","\n","        self.cost = norm * tf.reduce_mean(\n","            tf.nn.weighted_cross_entropy_with_logits(\n","                logits=preds_sub, targets=labels_sub, pos_weight=pos_weight))\n","        self.optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)  # Adam Optimizer\n","\n","        self.opt_op = self.optimizer.minimize(self.cost)\n","        self.grads_vars = self.optimizer.compute_gradients(self.cost)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MoGBq3WYrPhr","colab_type":"code","colab":{}},"source":["adj = load_data()\n","num_nodes = adj.shape[0]\n","num_edges = adj.sum()\n","# Featureless\n","features = sparse_to_tuple(sp.identity(num_nodes))\n","num_features = features[2][1]\n","features_nonzero = features[1].shape[0]\n","\n","# Store original adjacency matrix (without diagonal entries) for later\n","adj_orig = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n","adj_orig.eliminate_zeros()\n","\n","adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n","adj = adj_train\n","\n","adj_norm = preprocess_graph(adj)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m-6ls_UgrROl","colab_type":"code","outputId":"b4f8173c-1c89-429a-ab22-61a34040fe3f","executionInfo":{"status":"ok","timestamp":1576852271600,"user_tz":-540,"elapsed":1905,"user":{"displayName":"Jinwoo Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhgJSHrbMreTqBnmwR9bPABANy6TFKVVUvgM3_Gg=s64","userId":"09499597083311632056"}},"colab":{"base_uri":"https://localhost:8080/","height":142}},"source":["tf.app.flags.DEFINE_string('f', '', 'kernel')\n","\n","# Define placeholders\n","placeholders = {\n","    'features': tf.sparse_placeholder(tf.float32),\n","    'adj': tf.sparse_placeholder(tf.float32),\n","    'adj_orig': tf.sparse_placeholder(tf.float32),\n","    'dropout': tf.placeholder_with_default(0., shape=())\n","}\n","\n","# Create model\n","model = GCNModel(placeholders, num_features, features_nonzero, name='yeast_gcn')\n","\n","# Create optimizer\n","with tf.name_scope('optimizer'):\n","    opt = Optimizer(\n","        preds=model.reconstructions,\n","        labels=tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'], validate_indices=False), [-1]),\n","        num_nodes=num_nodes,\n","        num_edges=num_edges)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-18-e06c5c3ce1fe>:16: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From <ipython-input-20-6b2d56f4d63a>:11: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.\n","Instructions for updating:\n","targets is deprecated, use labels instead\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WNFeaCiQrStE","colab_type":"code","outputId":"c22015ae-dbac-49ee-9ed4-271f92354890","executionInfo":{"status":"ok","timestamp":1576852319349,"user_tz":-540,"elapsed":44222,"user":{"displayName":"Jinwoo Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhgJSHrbMreTqBnmwR9bPABANy6TFKVVUvgM3_Gg=s64","userId":"09499597083311632056"}},"colab":{"base_uri":"https://localhost:8080/","height":422}},"source":["# Initialize session\n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","\n","adj_label = adj_train + sp.eye(adj_train.shape[0])\n","adj_label = sparse_to_tuple(adj_label)\n","\n","# Train model\n","for epoch in range(FLAGS.epochs):\n","    t = time.time()\n","    # Construct feed dictionary\n","    feed_dict = construct_feed_dict(adj_norm, adj_label, features, placeholders)\n","    feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n","    # One update of parameter matrices\n","    _, avg_cost = sess.run([opt.opt_op, opt.cost], feed_dict=feed_dict)\n","    # Performance on validation set\n","    roc_curr, ap_curr = get_roc_score(val_edges, val_edges_false)\n","\n","    print(\"Epoch:\", '%04d' % (epoch + 1), \n","          \"train_loss=\", \"{:.5f}\".format(avg_cost),\n","          \"val_roc=\", \"{:.5f}\".format(roc_curr),\n","          \"val_ap=\", \"{:.5f}\".format(ap_curr),\n","          \"time=\", \"{:.5f}\".format(time.time() - t))\n","\n","print('Optimization Finished!')\n","\n","roc_score, ap_score = get_roc_score(test_edges, test_edges_false)\n","print('Test ROC score: {:.5f}'.format(roc_score))\n","print('Test AP score: {:.5f}'.format(ap_score))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 0001 train_loss= 0.68120 val_roc= 0.85129 val_ap= 0.83257 time= 3.05986\n","Epoch: 0002 train_loss= 0.68118 val_roc= 0.87722 val_ap= 0.86710 time= 2.01954\n","Epoch: 0003 train_loss= 0.68099 val_roc= 0.88006 val_ap= 0.86946 time= 1.98707\n","Epoch: 0004 train_loss= 0.68016 val_roc= 0.88034 val_ap= 0.86959 time= 1.99548\n","Epoch: 0005 train_loss= 0.67808 val_roc= 0.88035 val_ap= 0.86959 time= 1.98663\n","Epoch: 0006 train_loss= 0.67390 val_roc= 0.88033 val_ap= 0.86957 time= 2.00177\n","Epoch: 0007 train_loss= 0.66726 val_roc= 0.88032 val_ap= 0.86957 time= 2.03849\n","Epoch: 0008 train_loss= 0.65746 val_roc= 0.88031 val_ap= 0.86956 time= 2.05721\n","Epoch: 0009 train_loss= 0.64487 val_roc= 0.88030 val_ap= 0.86956 time= 2.00696\n","Epoch: 0010 train_loss= 0.62995 val_roc= 0.88030 val_ap= 0.86955 time= 1.99635\n","Epoch: 0011 train_loss= 0.61651 val_roc= 0.88029 val_ap= 0.86955 time= 1.99818\n","Epoch: 0012 train_loss= 0.61301 val_roc= 0.88028 val_ap= 0.86955 time= 2.02541\n","Epoch: 0013 train_loss= 0.62198 val_roc= 0.88025 val_ap= 0.86956 time= 2.02772\n","Epoch: 0014 train_loss= 0.62984 val_roc= 0.88021 val_ap= 0.86955 time= 2.00037\n","Epoch: 0015 train_loss= 0.62564 val_roc= 0.88016 val_ap= 0.86954 time= 1.96641\n","Epoch: 0016 train_loss= 0.61824 val_roc= 0.88008 val_ap= 0.86952 time= 2.00930\n","Epoch: 0017 train_loss= 0.61111 val_roc= 0.87996 val_ap= 0.86947 time= 1.97144\n","Epoch: 0018 train_loss= 0.60891 val_roc= 0.87979 val_ap= 0.86938 time= 1.96162\n","Epoch: 0019 train_loss= 0.61046 val_roc= 0.87963 val_ap= 0.86929 time= 2.02396\n","Epoch: 0020 train_loss= 0.61199 val_roc= 0.87950 val_ap= 0.86921 time= 2.03030\n","Optimization Finished!\n","Test ROC score: 0.87630\n","Test AP score: 0.86619\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gNfjjf8Mrycf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}