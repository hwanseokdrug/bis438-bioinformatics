{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"project_1_ppi.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"3EuRu4pROaS6","colab_type":"text"},"source":["#**Project 1. Graph Convolutional Prediction of Protein Interactions in Yeast**\n","\n","- Link prediction problem on unweighted and undirected networks\n","\n","- Yeast PPI network -> prediction of new protein-pretein interactions"]},{"cell_type":"code","metadata":{"id":"yQ5tQhWyBMuz","colab_type":"code","outputId":"a043dcab-679c-4597-dd1d-9bcea66bb02b","executionInfo":{"status":"ok","timestamp":1577276920197,"user_tz":-540,"elapsed":1451,"user":{"displayName":"Seunghwan Jung","photoUrl":"","userId":"08735151494823615326"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# connect to google drive\n","from google.colab import drive\n","\n","drive.mount('/gdrive')\n","gdrive_root = '/gdrive/My Drive'\n","\n","########################################################################################\n","# SET WORKING DIRECTORY TO PROJECT FOLDER BEFORE RUNNING!!\n","wd = gdrive_root + '/project5/'\n","########################################################################################"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i8gvj_TUCRqH","colab_type":"code","outputId":"4ee0b3be-cad0-4ed4-c4b9-94ea10104f07","executionInfo":{"status":"ok","timestamp":1577276920781,"user_tz":-540,"elapsed":2021,"user":{"displayName":"Seunghwan Jung","photoUrl":"","userId":"08735151494823615326"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# import libraries\n","import time\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import numpy as np\n","import scipy.sparse as sp\n","import networkx as nx\n","\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import average_precision_score\n","import matplotlib.pyplot as plt\n","\n","# set random seed\n","seed = 123\n","np.random.seed(seed)\n","torch.manual_seed(seed)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fc9956dabd0>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"EEQhG1ADOhkG","colab_type":"text"},"source":["# **Hyperparameters + helper functions**"]},{"cell_type":"code","metadata":{"id":"cxRI17thCjxT","colab_type":"code","outputId":"05d5d838-ca43-4a88-a33b-46afcf9b6f3f","executionInfo":{"status":"ok","timestamp":1577276920781,"user_tz":-540,"elapsed":2012,"user":{"displayName":"Seunghwan Jung","photoUrl":"","userId":"08735151494823615326"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","# set hyperparameters\n","hp = {}\n","hp['learning_rate'] = 0.01\n","hp['epochs'] = 20\n","hp['hidden1'] = 32\n","hp['hidden2'] = 16\n","hp['dropout'] = 0.1\n","\n","print(hp)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["{'learning_rate': 0.01, 'epochs': 20, 'hidden1': 32, 'hidden2': 16, 'dropout': 0.1}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pGkPN4kvDyx8","colab_type":"code","colab":{}},"source":["# functions for data processing\n","\n","# load adjacency matrix\n","def load_data():\n","  g = nx.read_edgelist(wd + 'yeast.edgelist')\n","  # g: networkx Graph object\n","  adj = nx.adjacency_matrix(g)\n","  # adj: SciPy sparse matrix\n","  return adj\n","  \n","\n","# normalize adjacency matrix\n","def preprocess_graph(adj):\n","  # convert adj to COO format\n","  adj = sp.coo_matrix(adj)\n","  # add sparse identity matrix\n","  # for considering recurrent interaction during convolution\n","  adj_ = adj + sp.eye(adj.shape[0])\n","\n","  # node degree vector for normalization\n","  rowsum = np.array(adj_.sum(1))\n","  degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n","\n","  # sparse normalized adjacency matrix\n","  adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n","  return adj_normalized\n","\n","\n","# convert sparse matrix to sparse torch tensor\n","def sparse_to_tensor(sparse_mx):\n","  # convert to COO format\n","  if not sp.isspmatrix_coo(sparse_mx):\n","    sparse_mx = sparse_mx.tocoo()\n","  \n","  # get arguments for tensor initialization\n","  values = sparse_mx.data\n","  indices = np.vstack((sparse_mx.row, sparse_mx.col))\n","  v = torch.FloatTensor(values)\n","  i = torch.LongTensor(indices)\n","  shape = sparse_mx.shape\n","  \n","  # make sparse tensor\n","  sparse_tensor = torch.sparse.FloatTensor(i, v, torch.Size(shape))\n","  return sparse_tensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tGH05sLvNOO7","colab_type":"code","colab":{}},"source":["# functions for dataset construction\n","\n","# converting sparse matrix\n","def sparse_to_tuple(sparse_mx):\n","  if not sp.isspmatrix_coo(sparse_mx):\n","    sparse_mx = sparse_mx.tocoo()\n","  # coords: rows are coordinates\n","  coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n","  values = sparse_mx.data\n","  shape = sparse_mx.shape\n","  return coords, values, shape\n","\n","\n","# build test/val set with 2% positive links\n","def mask_test_edges(adj):\n","  # remove diagonal elements\n","  adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n","  adj.eliminate_zeros()\n","\n","  # convert to upper triangular matrix\n","  adj_triu = sp.triu(adj)\n"," \n","  # get coordinates of unique, non-recurrent edges\n","  adj_tuple = sparse_to_tuple(adj_triu)\n","  edges = adj_tuple[0]\n","  \n","  # get coordinates of all nonzero elements from raw adjacency matrix\n","  edges_all = sparse_to_tuple(adj)[0]\n","  \n","  # test/val set size\n","  num_test = int(np.floor(edges.shape[0] / 50.))\n","  num_val = int(np.floor(edges.shape[0] / 50.))\n","\n","  # random index selection\n","  all_edge_idx = np.linspace(0,edges.shape[0],edges.shape[0],\n","                             endpoint=False).astype(int)\n","  np.random.shuffle(all_edge_idx)\n","  val_edge_idx = all_edge_idx[:num_val]\n","  test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n","  \n","  # edge selection\n","  # array of coordinates\n","  test_edges = edges[test_edge_idx]\n","  val_edges = edges[val_edge_idx]\n","  train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n","\n","  # auxiliary function\n","  # a: 1D array of two ints, b: 2D array of coordinates\n","  def ismember(a, b):\n","    rows_close = np.all((a - b[:, None]) == 0, axis=-1)\n","    return np.any(rows_close)\n","\n","  # randomly selected unique negative edges for test set\n","  test_edges_false = []\n","\n","  # generate until negative set size same as positive set\n","  while len(test_edges_false) < len(test_edges):\n","    # number of random set to generate\n","    n_rnd = len(test_edges) - len(test_edges_false)\n","    # randomly generate edges\n","    rnd = np.random.randint(0, adj.shape[0], size=2 * n_rnd)\n","    idxs_i = rnd[:n_rnd]                                        \n","    idxs_j = rnd[n_rnd:]\n","    # append to negative set if...\n","    for i in range(n_rnd):\n","      idx_i = idxs_i[i]\n","      idx_j = idxs_j[i]\n","      # not a recurrent edge\n","      if idx_i == idx_j:\n","        continue\n","      # not in raw adjacency matrix\n","      if ismember([idx_i, idx_j], edges_all):\n","        continue\n","      if test_edges_false:\n","        # not already in negative edge list\n","        if ismember([idx_j, idx_i], np.array(test_edges_false)):\n","          continue\n","        if ismember([idx_i, idx_j], np.array(test_edges_false)):\n","          continue\n","      # append to negative set\n","      test_edges_false.append([idx_i, idx_j])\n","\n","  # randomly selected unique negative edges for val set\n","  val_edges_false = []\n","  # generate until negative set size same as positive set\n","  while len(val_edges_false) < len(val_edges):\n","    # number of random set to generate\n","    n_rnd = len(val_edges) - len(val_edges_false)\n","    # randomly generate edges\n","    rnd = np.random.randint(0, adj.shape[0], size=2 * n_rnd)\n","    idxs_i = rnd[:n_rnd]                                        \n","    idxs_j = rnd[n_rnd:]\n","    # append to negative set if...\n","    for i in range(n_rnd):\n","      idx_i = idxs_i[i]\n","      idx_j = idxs_j[i]\n","      # not a recurrent edge\n","      if idx_i == idx_j:\n","        continue\n","      # not in train edge list\n","      if ismember([idx_i, idx_j], train_edges):\n","        continue\n","      if ismember([idx_j, idx_i], train_edges):\n","        continue\n","      # not in val edge list\n","      if ismember([idx_i, idx_j], val_edges):\n","        continue\n","      if ismember([idx_j, idx_i], val_edges):\n","        continue\n","      if val_edges_false:\n","        # not already in val negative edge list\n","        if ismember([idx_j, idx_i], np.array(val_edges_false)):\n","          continue\n","        if ismember([idx_i, idx_j], np.array(val_edges_false)):\n","          continue\n","      # append to negative set\n","      val_edges_false.append([idx_i, idx_j])\n","\n","  # re-build sparse adj matrix\n","  data = np.ones(train_edges.shape[0])\n","  adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n","  adj_train = adj_train + adj_train.T\n","\n","  return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7mvs0tMTOnUv","colab_type":"text"},"source":["# **Pytorch implementation of GCN modules**"]},{"cell_type":"code","metadata":{"id":"eT_kZIL9WRUp","colab_type":"code","colab":{}},"source":["# dropout for sparse input\n","def dropout_sparse(x, p, num_nonzero_elems):\n","  # current pytorch sparse tensors does not allow indexing\n","  coo = x.clone().detach()._indices().numpy()\n","  drop_num = int(num_nonzero_elems*p)\n","  drop_idx = np.random.choice(coo.shape[1], drop_num, replace=False)\n","  drop_coo = coo[:,drop_idx].T\n","  x = x.to_dense()\n","  x[drop_coo[:,0],drop_coo[:,1]] = 0\n","  indices = torch.nonzero(x).t()\n","  values = x[indices[0], indices[1]]\n","  o = torch.sparse.FloatTensor(indices, values, x.size())*(1./(1-p))\n","  return o\n","\n","# graph convolution layer\n","# works both for sparse and dense input\n","class GraphConvolution(nn.Module):\n","  def __init__(self, input_dim, output_dim, adj, dropout=0, sparse_input=False):\n","    super().__init__()\n","    print(f'GraphConvolution object initialized with input dim = {input_dim}, output dim = {output_dim}')\n","    self.sparse_input = sparse_input\n","    self.input_dim = input_dim\n","    self.output_dim = output_dim\n","    self.p = dropout\n","    self.adj = adj # normalized adjacency matrix (sparse tensor)\n","    \n","    self.w = nn.Parameter(torch.empty(output_dim, input_dim)) # feature weight matrix (dense tensor)\n","    nn.init.xavier_normal_(self.w)\n","    self.relu = nn.ReLU() # non-linearity\n","    self.dropout = nn.Dropout(p=self.p) # dropout\n","\n","  def forward(self, x):\n","    # input, output tensor shapes: (num_features, num_nodes)\n","    num_nodes = x.shape[1]\n","    if x.shape[0] != self.input_dim:\n","      raise RuntimeError(\"input feature dimension not matched to input_dim argument\")\n","\n","    # forward\n","    if self.sparse_input:\n","      x = dropout_sparse(x, p=self.p, num_nonzero_elems=x._values().shape[0])\n","    else:\n","      x = self.dropout(x)\n","    x = torch.transpose(x, 0, 1) # (num_nodes, input_dim)\n","    x = torch.mm(x, torch.transpose(self.w, 0, 1)) # (num_nodes, output_dim)\n","    x = torch.mm(self.adj, x) # (num_nodes, output_dim)\n","    x = torch.transpose(x, 0, 1) # (output_dim, num_nodes)\n","    o = self.relu(x)\n","    return o\n","  \n","# decoder layer for link prediction\n","class InnerProductDecoder(nn.Module):\n","  def __init__(self, input_dim, dropout=0):\n","    super().__init__()\n","    print(f'InnerProductDecoder object initialized with input dim = {input_dim}')\n","    self.input_dim = input_dim\n","    self.dropout = nn.Dropout(p=dropout)\n","\n","  def forward(self, x):\n","    # input tensor shape: (num_features, num_nodes)\n","    x = self.dropout(x)\n","    xT = torch.transpose(x, 0, 1) # (num_nodes, input_dim)\n","    x = torch.mm(xT, x) # (num_nodes, num_nodes)\n","    o = torch.flatten(x)\n","    return o"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bbRNe540jfFc","colab_type":"code","colab":{}},"source":["class GCNModel(nn.Module):\n","  def __init__(self, input_dim, adj):\n","    super().__init__()\n","    print(f'GCNModel object initialized with input dim = {input_dim}')\n","    self.input_dim = input_dim\n","    self.hp = hp # hyperparameters\n","    self.adj = adj # normalized adjacency matrix\n","\n","    self.gc1 = GraphConvolution(input_dim=self.input_dim,\n","                                output_dim=self.hp['hidden1'],\n","                                adj=self.adj,\n","                                dropout=self.hp['dropout'],\n","                                sparse_input=True)\n","    self.gc2 = GraphConvolution(input_dim=self.hp['hidden1'],\n","                                output_dim=self.hp['hidden2'],\n","                                adj=self.adj,\n","                                dropout=self.hp['dropout'],\n","                                sparse_input=False)\n","    self.dec = InnerProductDecoder(input_dim=self.hp['hidden2'],\n","                                   dropout=self.hp['dropout'])\n","    \n","  def forward(self, x):\n","    # input tensor shape: (input_dim, num_nodes)\n","    x = self.gc1(x)\n","    x = self.gc2(x)\n","    o = self.dec(x)\n","    # output tensor shape: (num_nodes*num_nodes, )\n","    return o"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"on_KtAGdO0ee","colab_type":"text"},"source":["# **Main training routine**"]},{"cell_type":"code","metadata":{"id":"8GIKuD7_mJY6","colab_type":"code","colab":{}},"source":["# load adjacency matrix\n","adj = load_data() # raw adjacency matrix\n","num_nodes = adj.shape[0]\n","num_edges = np.sum(adj)\n","\n","# train / val / test data\n","adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C9LMC_mwtYRq","colab_type":"code","outputId":"c5c7bbc8-6294-4ba0-d97d-2ecb026aa1f2","executionInfo":{"status":"ok","timestamp":1577277276451,"user_tz":-540,"elapsed":357610,"user":{"displayName":"Seunghwan Jung","photoUrl":"","userId":"08735151494823615326"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# input feature: none (node index one-hot)\n","features = sp.identity(num_nodes) # coords, values, shape\n","num_features = features.shape[1]\n","\n","# normalized train adjacency matrix for graph convolution\n","adj_norm = preprocess_graph(adj_train)\n","adj_tensor = sparse_to_tensor(adj_norm)\n","adj_tensor.requires_grad = False\n","\n","# initialize model\n","model = GCNModel(input_dim=num_features, adj=adj_tensor)\n","\n","# set optimizer\n","optimizer = optim.Adam(model.parameters(), lr=hp['learning_rate'])\n","\n","# define loss\n","def compute_loss(output, labels, num_nodes, num_edges):\n","  pos_weight = torch.ones([num_nodes*num_nodes])*float(num_nodes**2 - num_edges) / num_edges\n","  norm = num_nodes**2 / float((num_nodes**2 - num_edges) * 2)\n","  criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction='mean')\n","  loss = norm*criterion(output.view((1, -1)),\n","                        labels.view((1, -1)))\n","  return loss\n","\n","# evaluation metric\n","def get_roc_score(edges_pos, edges_neg, adj_orig, adj_label):\n","  # forward pass\n","  adj_rec = model(feat_tensor).view(adj_orig.shape).detach().numpy()\n","\n","  def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","  # prediction of the model on given edge set\n","  preds_pos = []\n","  pos = []\n","  for e in edges_pos:\n","    preds_pos.append(sigmoid(adj_rec[e[0], e[1]]))\n","    pos.append(adj_orig[e[0], e[1]])\n","  \n","  preds_neg = []\n","  neg = []\n","  for e in edges_neg:\n","    preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n","    neg.append(adj_orig[e[0], e[1]])\n","\n","  preds_all = np.hstack([preds_pos, preds_neg])\n","  labels_all = np.hstack([np.ones(len(preds_pos)), np.zeros(len(preds_pos))])\n","  roc_score = roc_auc_score(labels_all, preds_all)\n","  ap_score = average_precision_score(labels_all, preds_all)\n","\n","  return roc_score, ap_score"],"execution_count":17,"outputs":[{"output_type":"stream","text":["GCNModel object initialized with input dim = 6526\n","GraphConvolution object initialized with input dim = 6526, output dim = 32\n","GraphConvolution object initialized with input dim = 32, output dim = 16\n","InnerProductDecoder object initialized with input dim = 16\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yuTEmuOwr45X","colab_type":"code","outputId":"6bfdd75a-86d0-43e0-d59b-548f5a10237a","executionInfo":{"status":"ok","timestamp":1577277323776,"user_tz":-540,"elapsed":404929,"user":{"displayName":"Seunghwan Jung","photoUrl":"","userId":"08735151494823615326"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# set input / target\n","feat_tensor = sparse_to_tensor(features)\n","\n","# target label\n","adj_label = adj_train + sp.eye(adj_train.shape[0])\n","adj_label = torch.flatten(sparse_to_tensor(adj_label).to_dense())\n","adj_label.requires_grad = False\n","\n","# diagonal-removed adjacency matrix for ROC curve computation\n","adj_orig = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n","\n","print('Preformance of initialized model')\n","roc_score, ap_score = get_roc_score(test_edges, test_edges_false, adj_orig, adj_label)\n","print('Initial ROC score: {:.5f}'.format(roc_score))\n","print('Initial AP score: {:.5f}'.format(ap_score))\n","\n","for epoch in range(hp['epochs']):\n","  t = time.time()\n","  # set model to train mode\n","  model.train()\n","  # flush gradients\n","  optimizer.zero_grad()\n","\n","  # forward pass\n","  output = model(feat_tensor)\n","  # compute loss\n","  loss = compute_loss(output=output, labels=adj_label, num_nodes=num_nodes, num_edges=num_edges)\n","  # backward pass\n","  loss.backward()\n","  print(f'\\ncheck mean gradient: GC1 {np.mean(model.gc1.w.grad.clone().detach().numpy())}, GC2 {np.mean(model.gc2.w.grad.clone().detach().numpy())}')\n","  optimizer.step()\n","  \n","  # evaluate\n","  model.eval()\n","  roc_curr, ap_curr = get_roc_score(val_edges, val_edges_false, adj_orig, adj_label)\n","  # log\n","  print(\"Epoch:\", '%04d' % (epoch + 1),\n","        \"train_loss=\", \"{:.5f}\".format(loss),\n","        \"val_roc=\", \"{:.5f}\".format(roc_curr),\n","        \"val_ap=\", \"{:.5f}\".format(ap_curr),\n","        \"time=\", \"{:.5f}\".format(time.time() - t))\n","\n","print('Optimization finished!')\n","roc_score, ap_score = get_roc_score(test_edges, test_edges_false, adj_orig, adj_label)\n","print('Test ROC score: {:.5f}'.format(roc_score))\n","print('Test AP score: {:.5f}'.format(ap_score))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Preformance of initialized model\n","Initial ROC score: 0.74474\n","Initial AP score: 0.65676\n","\n","check mean gradient: GC1 -5.23995202783567e-09, GC2 -4.005696041531337e-08\n","Epoch: 0001 train_loss= 0.69499 val_roc= 0.87706 val_ap= 0.86806 time= 2.62946\n","\n","check mean gradient: GC1 -2.9425973480101675e-07, GC2 -6.730005225108471e-06\n","Epoch: 0002 train_loss= 0.69475 val_roc= 0.87835 val_ap= 0.86890 time= 2.24086\n","\n","check mean gradient: GC1 -7.717378025517974e-07, GC2 -3.844379534712061e-05\n","Epoch: 0003 train_loss= 0.69343 val_roc= 0.87828 val_ap= 0.86882 time= 2.24154\n","\n","check mean gradient: GC1 -1.450709987693699e-06, GC2 -0.00011235527927055955\n","Epoch: 0004 train_loss= 0.69058 val_roc= 0.87817 val_ap= 0.86880 time= 2.28471\n","\n","check mean gradient: GC1 -2.2823173821961973e-06, GC2 -0.000237693777307868\n","Epoch: 0005 train_loss= 0.68565 val_roc= 0.87816 val_ap= 0.86875 time= 2.23037\n","\n","check mean gradient: GC1 -3.163746669088141e-06, GC2 -0.000403517740778625\n","Epoch: 0006 train_loss= 0.67897 val_roc= 0.87816 val_ap= 0.86874 time= 2.24182\n","\n","check mean gradient: GC1 -4.081542101630475e-06, GC2 -0.0006102801417000592\n","Epoch: 0007 train_loss= 0.66916 val_roc= 0.87815 val_ap= 0.86873 time= 2.24443\n","\n","check mean gradient: GC1 -4.703348167822696e-06, GC2 -0.0007974720792844892\n","Epoch: 0008 train_loss= 0.65630 val_roc= 0.87816 val_ap= 0.86876 time= 2.20282\n","\n","check mean gradient: GC1 -4.8023907766037155e-06, GC2 -0.0009027764317579567\n","Epoch: 0009 train_loss= 0.64144 val_roc= 0.87809 val_ap= 0.86872 time= 2.23171\n","\n","check mean gradient: GC1 -3.84079294235562e-06, GC2 -0.0007896953029558063\n","Epoch: 0010 train_loss= 0.62691 val_roc= 0.87809 val_ap= 0.86872 time= 2.24689\n","\n","check mean gradient: GC1 -1.100781901186565e-06, GC2 -0.00025949609698727727\n","Epoch: 0011 train_loss= 0.61889 val_roc= 0.87808 val_ap= 0.86872 time= 2.24964\n","\n","check mean gradient: GC1 3.2759471650933847e-06, GC2 0.0007188767194747925\n","Epoch: 0012 train_loss= 0.62018 val_roc= 0.87807 val_ap= 0.86869 time= 2.20174\n","\n","check mean gradient: GC1 7.187014944065595e-06, GC2 0.0016542848898097873\n","Epoch: 0013 train_loss= 0.62959 val_roc= 0.87809 val_ap= 0.86877 time= 2.20067\n","\n","check mean gradient: GC1 8.13396673038369e-06, GC2 0.0019071362912654877\n","Epoch: 0014 train_loss= 0.63260 val_roc= 0.87811 val_ap= 0.86877 time= 2.25437\n","\n","check mean gradient: GC1 6.71733414492337e-06, GC2 0.0015796073712408543\n","Epoch: 0015 train_loss= 0.62799 val_roc= 0.87801 val_ap= 0.86876 time= 2.22815\n","\n","check mean gradient: GC1 4.369630005385261e-06, GC2 0.0010589309968054295\n","Epoch: 0016 train_loss= 0.62209 val_roc= 0.87801 val_ap= 0.86870 time= 2.26088\n","\n","check mean gradient: GC1 1.5845981806705822e-06, GC2 0.0004348377697169781\n","Epoch: 0017 train_loss= 0.61680 val_roc= 0.87792 val_ap= 0.86863 time= 2.20260\n","\n","check mean gradient: GC1 -4.581357870847569e-07, GC2 -0.00018452032236382365\n","Epoch: 0018 train_loss= 0.61596 val_roc= 0.87785 val_ap= 0.86862 time= 2.21536\n","\n","check mean gradient: GC1 -1.5543004110440961e-06, GC2 -0.0005894254427403212\n","Epoch: 0019 train_loss= 0.61873 val_roc= 0.87765 val_ap= 0.86855 time= 2.26231\n","\n","check mean gradient: GC1 -2.1309920157364104e-06, GC2 -0.0007192662451416254\n","Epoch: 0020 train_loss= 0.61968 val_roc= 0.87763 val_ap= 0.86852 time= 2.19537\n","Optimization finished!\n","Test ROC score: 0.87741\n","Test AP score: 0.86273\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1DE7bXzUS0nl","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}